\doxysection{microgradpp\+::core\+::Core\+Re\+LU Class Reference}
\hypertarget{classmicrogradpp_1_1core_1_1_core_re_l_u}{}\label{classmicrogradpp_1_1core_1_1_core_re_l_u}\index{microgradpp::core::CoreReLU@{microgradpp::core::CoreReLU}}


Implements the Re\+LU activation function as a layer in a neural network.  




{\ttfamily \#include $<$Core\+Re\+LU.\+hpp$>$}



Inheritance diagram for microgradpp\+::core\+::Core\+Re\+LU\+:
% FIG 0


Collaboration diagram for microgradpp\+::core\+::Core\+Re\+LU\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
void \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_core_re_l_u_a356b40d5d3646e5667a0a40274459080}{print}} () const override final
\begin{DoxyCompactList}\small\item\em Prints layer information, displaying that this is a Re\+LU layer. \end{DoxyCompactList}\item 
\mbox{\hyperlink{classmicrogradpp_1_1___tensor1_d}{Tensor1D}} \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_core_re_l_u_a2250d924efa54731bd84ef245afe371b}{operator()}} (const \mbox{\hyperlink{classmicrogradpp_1_1___tensor1_d}{Tensor1D}} \&in) override
\begin{DoxyCompactList}\small\item\em Applies the Re\+LU activation function to each element in the input tensor. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core}{microgradpp\+::core\+::\+Mpp\+Core}}}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_a72e0437cdd12b4dbfffe5db2cf468670}{Mpp\+Core}} ()=default
\begin{DoxyCompactList}\small\item\em Default constructor for {\ttfamily \doxylink{classmicrogradpp_1_1core_1_1_mpp_core}{Mpp\+Core}}. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_a71dcf1cb4282f9d2b946672ea85ce96c}{zero\+Grad}} ()
\begin{DoxyCompactList}\small\item\em Resets gradients for all parameters in the layer. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_a43e7bdcf0f8565e5cc46f65541aa5098}{print\+Parameters}} () const
\begin{DoxyCompactList}\small\item\em Prints parameter information for the layer. \end{DoxyCompactList}\item 
virtual \+\_\+\+\_\+\+MICROGRADPP\+\_\+\+NO\+\_\+\+DISCARD\+\_\+\+\_\+ std\+::vector$<$ \mbox{\hyperlink{classmicrogradpp_1_1_value}{Value}} \texorpdfstring{$\ast$}{*} $>$ \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_a807893ada4561094454472a6ada4d8ea}{parameters}} () const
\begin{DoxyCompactList}\small\item\em Returns a list of pointers to the layer\textquotesingle{}s parameters. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Implements the Re\+LU activation function as a layer in a neural network. 

The {\ttfamily \doxylink{classmicrogradpp_1_1core_1_1_core_re_l_u}{Core\+Re\+LU}} class is a layer that applies the Re\+LU activation function element-\/wise to an input tensor, setting all negative values to zero. 

\doxysubsection{Member Function Documentation}
\Hypertarget{classmicrogradpp_1_1core_1_1_core_re_l_u_a2250d924efa54731bd84ef245afe371b}\index{microgradpp::core::CoreReLU@{microgradpp::core::CoreReLU}!operator()@{operator()}}
\index{operator()@{operator()}!microgradpp::core::CoreReLU@{microgradpp::core::CoreReLU}}
\doxysubsubsection{\texorpdfstring{operator()()}{operator()()}}
{\footnotesize\ttfamily \label{classmicrogradpp_1_1core_1_1_core_re_l_u_a2250d924efa54731bd84ef245afe371b} 
\mbox{\hyperlink{classmicrogradpp_1_1___tensor1_d}{Tensor1D}} microgradpp\+::core\+::\+Core\+Re\+LU\+::operator() (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classmicrogradpp_1_1___tensor1_d}{Tensor1D}} \&}]{in}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [override]}, {\ttfamily [virtual]}}



Applies the Re\+LU activation function to each element in the input tensor. 

Uses the Re\+LU function, defined in the {\ttfamily \doxylink{classmicrogradpp_1_1_activation}{Activation}} class, to process each element in the input tensor. This is achieved by iterating through the tensor and replacing negative values with zero while keeping positive values unchanged.


\begin{DoxyParams}{Parameters}
{\em in} & Input tensor for which Re\+LU activation is applied. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Tensor1D Output tensor where each element is the result of applying Re\+LU to the corresponding input element. 
\end{DoxyReturn}


Implements \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_aa346e478c08b034fcbc646502c222873}{microgradpp\+::core\+::\+Mpp\+Core}}.

\Hypertarget{classmicrogradpp_1_1core_1_1_core_re_l_u_a356b40d5d3646e5667a0a40274459080}\index{microgradpp::core::CoreReLU@{microgradpp::core::CoreReLU}!print@{print}}
\index{print@{print}!microgradpp::core::CoreReLU@{microgradpp::core::CoreReLU}}
\doxysubsubsection{\texorpdfstring{print()}{print()}}
{\footnotesize\ttfamily \label{classmicrogradpp_1_1core_1_1_core_re_l_u_a356b40d5d3646e5667a0a40274459080} 
void microgradpp\+::core\+::\+Core\+Re\+LU\+::print (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [final]}, {\ttfamily [override]}, {\ttfamily [virtual]}}



Prints layer information, displaying that this is a Re\+LU layer. 

Outputs "{}\+Re\+LU Layer"{} to the standard console to indicate the type of layer. 

Implements \mbox{\hyperlink{classmicrogradpp_1_1core_1_1_mpp_core_a0ac1f62e1f93221c65514f2af702af14}{microgradpp\+::core\+::\+Mpp\+Core}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
include/core/\mbox{\hyperlink{_core_re_l_u_8hpp}{Core\+Re\+LU.\+hpp}}\end{DoxyCompactItemize}
